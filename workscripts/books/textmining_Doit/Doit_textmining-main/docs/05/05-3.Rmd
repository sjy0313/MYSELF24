---
title: "Do it! 쉽게 배우는 R 텍스트 마이닝 - 05 의미망 분석: <br> 어떤 맥락에서 단어를 썼을까?"
author: "김영우"
output:
  xaringan::moon_reader:
    seal: false
    css: ["default", "../css/custom.css"]
    lib_dir: libs
    chakra: ../libs/remark-latest.min.js
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      ratio: '16:10'
      navigation:
        scroll: true
editor_options: 
  chunk_output_type: console
---

```{r include=FALSE}
options(htmltools.dir.version = FALSE, 
        width = 80,
        # width = 70,
        
        max.print = 80,
        tibble.print_max = 40,
        
        tibble.width = 80,
        # tibble.width = 70,
        
        # pillar.min_chars = Inf, # tibble 문자 출력 제한
        servr.interval = 0.01) # Viewer 수정 반영 속도


knitr::opts_chunk$set(cache = T, warning = F, message = F, 
                      dpi = 300, fig.height = 4)
                      # out.width = "100%"

#xaringanExtra::use_tile_view()

library(knitr)
library(icon)
library(here)
```


```{r echo=FALSE}
rm(list = ls())

library(showtext)
font_add_google(name = "Nanum Gothic", family = "nanumgothic")
showtext_auto()
showtext_opts(dpi = 300) # opts_chunk$set(dpi=300)

# code highlighting
hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  x <- stringr::str_replace(x, "^[[:blank:]]?([^*].+?)[[:blank:]]*#<<[[:blank:]]*$", "*\\1")
  hook_source(x, options)
})


```

```{r echo=F}
# get data from prior rmd
load("05-2.rdata")

library(ggplot2)
library(dplyr)
library(tidytext)
library(stringr)
library(widyr)
library(ggraph)
```


class: title1

05-3 단어 간 상관 분석:   
Phi coefficient

---

##### 동시 출현 빈도의 한계
- 대부분의 단어와 자주 함께 사용되는 단어쌍 다수
    - ex) `"영화"-"기생충"`
- 다른 단어에 비해 상대적으로 자주 함께 사용된 단어가 무엇인지 살펴봐야 한다


--

##### 파이 계수(phi coefficient)
- 두 단어가 함께 사용되는 경우가 각각 사용되는 경우에 비해 얼마나 많은지 나타낸 지표
- 상대적으로 관련성이 큰 단어 파악하는데 활용
 - 어떤 단어와 자주 함께 사용되지만 다른 단어와는 자주 함께 사용되지 않는 단어
 
---

##### 파이 계수의 의미

- X, Y 두 단어가 있을 때, 여러 텍스트에서 두 단어의 사용 여부를 놓고 가능한 모든 경우
  - X, Y 모두 있음( $a$ )
  - X, Y 모두 없음( $d$ )
  - X만 있음( $b$ )
  - Y만 있음( $c$ )

<br10>

.center[
```{r, echo=F, out.width="60%", out.height="60%"}
include_graphics("../Image/etc/05_3_table1.png")
```
]


--

<br> 

$$\phi=\frac{ad-bc}{\sqrt{(a+b)(c+d)(a+c)(b+d)}}$$



---

##### 파이 계수의 의미

- -1 ~ +1
  - +1에 가까울수록 두 단어가 자주 함께 사용되어 관련성이 크다는 의미
  - -1에 가까울수록 함께 사용되는 경우가 드물어 관련성이 작다는 의미
  

---


#### 파이 계수 구하기

- `widyr::pairwise_cor()`
  - `item`: 단어
  - `feature`: 텍스트 구분 기준
  - `sort = T`: 파이 계수 높은순 정렬

.pull-left[

```{r word_cors, results='hide'}
word_cors <- comment %>%
  add_count(word) %>%
  filter(n >= 20) %>%
  pairwise_cor(item = word, 
               feature = id, 
               sort = T)

word_cors
```

`r fontawesome("lightbulb")`  `add_count()` 원자료에 빈도 나타낸 변수 추가

]

--

.pull-right[

```{r ref.label="word_cors", echo=F}

```


]


 
---


#### 특정 단어와 관련성이 큰 단어 살펴보기


.pull-left[

```{r}
word_cors %>%
  filter(item1 == "대한민국")
```
]

.pull-right[
```{r}
word_cors %>%
  filter(item1 == "역사")
```
]

---


#### 파이 계수로 막대 그래프 만들기

##### 1. 관심 단어별로 파이 계수가 큰 단어 추출하기

```{r}
# 관심 단어 목록 생성
target <- c("대한민국", "역사", "수상소감", "조국", "박근혜", "블랙리스트")

top_cors <- word_cors %>%
  filter(item1 %in% target) %>%
  group_by(item1) %>%
  slice_max(correlation, n = 8)
```

---


##### 2. 막대 그래프 만들기


```{r p_top_cors, fig.show='hide'}
# 그래프 순서 정하기
top_cors$item1 <- factor(top_cors$item1, levels = target)

library(ggplot2)
ggplot(top_cors, aes(x = reorder_within(item2, correlation, item1),
                 y = correlation,
                 fill = item1)) +
  geom_col(show.legend = F) +
  facet_wrap(~ item1, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(x = NULL) +
  theme(text = element_text(family = "nanumgothic"))
```

---

```{r ref.label="p_top_cors", echo=F, out.width="90%"}
```

---

#### 파이 계수로 네트워크 그래프 만들기


##### 1. 네트워크 그래프 데이터 만들기. 연결 중심성과 커뮤니티 추가하기

```{r}
set.seed(1234)
graph_cors <- word_cors %>%
  filter(correlation >= 0.15) %>%
  as_tbl_graph(directed = F) %>%
  mutate(centrality = centrality_degree(),
         group = as.factor(group_infomap()))
```

---

##### 2. 네트워크 그래프 만들기

```{r eval=F}
set.seed(1234)
ggraph(graph_cors, layout = "fr") +

  geom_edge_link(color = "gray50",
                 aes(edge_alpha = correlation,   # 엣지 명암
                     edge_width = correlation),  # 엣지 두께
                 show.legend = F) +              # 범례 삭제
  scale_edge_width(range = c(1, 4)) +            # 엣지 두께 범위

  geom_node_point(aes(size = centrality,
                      color = group),
                  show.legend = F) +
  scale_size(range = c(5, 10)) +

  geom_node_text(aes(label = name),
                 repel = T,
                 size = 5,
                 family = "nanumgothic") +

  theme_graph()
```

---


```{r, echo=F, out.width="80%"}
include_graphics("../Image/05/05_3_2.png")
```

---


##### 동시 출현 빈도, 파이 계수로 만든 네트워크 그래프의 차이점

<br10>

- **동시 출현 빈도**를 이용한 네트워크 그래프
  - 여러 단어와 자주 함께 사용된 단어쌍 중심으로 네트워크 형성
  - 노드 대부분이 서로 연결되어 구조가 복잡하고 군집이 잘 드러나지 않음
  - 자주 사용된 단어를 파악할 때 활용


--

<br>

- **파이 계수**를 이용한 네트워크 그래프
  - 다른 단어에 비해 상대적으로 자주 함께 사용된 단어쌍 중심으로 네트워크 형성
  - 관련성이 큰 단어끼리만 연결되어 단어 군집이 명확하게 드러남
  - 밀접하게 관련된 단어쌍 파악할 때 활용


---


##### 동시 출현 빈도, 파이 계수로 만든 네트워크 그래프의 차이점

<br10>

- **동시 출현 빈도**를 이용한 네트워크 그래프
  - .orange[**여러 단어와 자주 함께 사용된 단어쌍**] 중심으로 네트워크 형성
  - 노드 대부분이 서로 연결되어 구조가 복잡하고 군집이 잘 드러나지 않음
  - 자주 사용된 단어를 파악할 때 활용

<br>

- **파이 계수**를 이용한 네트워크 그래프
  - .orange[**다른 단어에 비해 상대적으로 자주 함께 사용된 단어쌍**] 중심으로 네트워크 형성
  - 관련성이 큰 단어끼리만 연결되어 단어 군집이 명확하게 드러남
  - 밀접하게 관련된 단어쌍 파악할 때 활용



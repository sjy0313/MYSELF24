qplot(data = mpg, x = drv, y=hwy, geom= "boxplot", colour = drv)
# 패키지 설치
install.packages("ggplot2")
# 패키지 로드
library(ggplot2)
x <- c("a", "a", "b", "c")
x
qplot(x)
# collapse 같은 parameter들을 활용하여 함수에 적용하기
# 그래프생성
qplot(data = mpg, x = drv, y=hwy, geom= "boxplot", colour = drv)
# + geom = line/ boxplot(상자그림 형태ㅡ , colour= drv별 색 표현 )
# 함수의 기능이 궁금할 떄
?qpl
mpg <- as.data.frame(ggplot2: :mpg)
mpg <- as.data.frame(ggplot2: mpg)
mpg <- as.data.frame(ggplot2: mpg)
library(ggplot2)
mpg <- as.data.frame(ggplot2: mpg)
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
mpg <- as.data.frame(ggplot2: mpg)
mpg <- as.data.frame(ggplot2:: mpg)
mpg
view(df_csv_exam)
# csv 파일 불러오기( 데이터를 불러올 떄 용량이 작기 때문에 자주 이용)
df_csv_exam <- read.csv("csv_exam.csv")
df_csv_exam
# r 내장 함수인 write.csv()로 파일 저장
write.csv(df_midterm, file = "df_midterm.csv") # file parameter로 파일명 지정/ header=F 변수명 없는 CSV파일 불러올떄
# rm() 데이터 삭제 할 때 ()
df_csv_exam <- read.csv("csv_exam.csv")
df_csv_exam
head(df_csv_exam) # 처음 부터 6행까지 출력
head(df_csv_exam,10)
tail(df_csv_exam) # 마지막 부분 6행 출력
view(df_csv_exam) # 데이터 확인 창
?mpg
install.packages("dplyr")
library(dplyr)
help(dplyr)
df_raw <- data.frame(var1=c(1,2,1), var2=c(2,3,2))
df_raw
df_new <- df_raw
df_new <- rename(df_new, v2 = var2) # var2 를 v2로 수정
df_new
df_new <- rename(df_new, v2 = var2) # var2 를 v2로 수정
rlang::last_trace()
rlang::last_trace(drop = FALSE)
df_new <- rename(df_new, v2 = var2) # var2 를 v2로 수정
# rename() 함수 :dplr 패키지
?rename
df_new <- rename(df_new, v2=var2) # var2 를 v2로 수정 (컬럼명 수정)
df_raw <- data.frame(var1=c(1,2,1), var2=c(2,3,2))
df_raw <- data.frame(var1=c(1,2,1), var2=c(2,3,2))
df_raw
df_new <- rename(df_new, v2=var2) # var2 를 v2로 수정 (컬럼명 수정)
df_new <- df_raw
df_new
df_new <- rename(df_new, v2=var2) # var2 를 v2로 수정 (컬럼명 수정)
df_new
df_raw
df_new
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
df <- data.frame(var1 = c(4,3,8),
var2 = c(2,6,1))
df
df$var_sum <- df$var1 + df$var2
df
# 조건문을 활용해 파생변수
mpg
summary(mpg$total)
mean(mpg$total)
mpg$total <- (mpg$cty + mpg$hwy)/2
head(mpg)
mean(mpg$total)
library(dplyr)
exam <- read.csv("csv_exam.csv")
exam
exam %>% filter(class == 1)
#filter and활용 (여러조건 동시 추출) : &/ or활용 (여러 조건 중 하나라도 충족되는 데이터 추출) :  |
# |를 활용하여 여러조건의 데이터 나열 가능
# %in% 기호를 이용하여 |를 이용할 떄 보다 간편하게 작성 가능
# ex
exam %>% filter(class %in% c(1,3,5))
math_higher10 <- exam %>% arrange(desc(math)) %>% head(10)
library(dplyr)
exam <- read.csv("csv_exam.csv")
exam
math_higher10 <- exam %>% arrange(desc(math)) %>% head(10)
math_higher10
exam %>%
select(id, class, math) %>%
arrange(desc(math)) %>%
head(10) %>%
arrange(id)
# 1   2     1   60
# 2   7     2   80
# 3   8     2   90
# 4  11     3   65
# 5  15     4   75
# 6  16     4   58
# 7  17     5   65
# 8  18     5   80
# 9  19     5   89
# 10 20     5   78
help(order)
vector_mathasc <- order(exam$math)
vector_mathasc
vector_mathdesc <- order(-exam$math)
vector_mathdesc
exam[math_order_asc,]
vector_math_order_asc <- order(exam$math)
vector_math_order_asc
exam[math_order_asc,]
math_order_desc <- order(-exam$math)
math_order_desc
exam[math_order_asc,]
math_order_asc <- order(exam$math)
math_order_asc
exam[math_order_asc,]
math_sort_asc <- sort(exam$math)
math_sort_asc
math_order_desc[order(math_order_desc, decreasing = T)]
m1[order(m1, decreasing = T)]
m1 <- exam %>% select(math)
m1[order(m1, decreasing = T)]
m1 <- exam %>% select(math)
m1 <- exam %>% select(math)
m1
m1[order(m1, decreasing = T)]
m1 <-arrange(desc(math)
m1
m1 <-arrange(desc(math))
m3 <- exam$math
m3
m3[order(m3, decreasing = T)]
class(m3)
m2 <-select(math)
m2 <-select(math)
m2 <-exam %>% select(math)
m2
class(m2)
m1 <-arrange(desc(math))
m1 <exam %>% arrange(desc(math))
m1 <- exam %>% arrange(desc(math))
m1
class(m1)
exam %>% mutate(total = math + english + science) %>% head
exam %>%
group_by(class) %>%
summarise(mean_math=mean(math))
mpg
mpg %>%
group_by(manufacturer) %>%
summarise(mean_cty = mean(cty)) %>%
head(10)
df <- df.frame(sex = ("M", "F", "NA", "M", "F"),
df <- data.frame(sex = ("M", "F", "NA", "M", "F"),
df <- data.frame(sex =c("M", "F", "NA", "M", "F"),
score = c(5, 4, 3, 4, NA))
df <- data.frame(sex = c("M", "F", "NA", "M", "F"),
score = c(5, 4, 3, 4, NA))
df
is.na(df)
table(is.na(df))
library(dplyr)
df %>% filter(is.na(score))
library(dplyr)
exam <- read.csv("csv_exam.csv")
exam
exam_teacher <- left_join(exam, teachers, by='class')
teachers <- data.frame(class= c(1,2,3,4),
teacher=c("kim", "lee", "park", "choi", "jung"))
teachers <- data.frame(class= c(1,2,3,4,5),
teacher=c("kim", "lee", "park", "choi", "jung"))
teachers
exam_teacher <- left_join(exam, teachers, by='class')
exam_teacher
exam_teacher <- right_join(exam, teachers, by='class')
exam_teacher
group_a <- data.frame(id= c(1,2,3,4,5),
test=c(60,70,80,90,85))
group_b <- data.frame(id= c(6,7,8,9,10),
test=c(70,83,65,95,80))
group_all
group_a <- data.frame(id= c(1,2,3,4,5),
test=c(60,70,80,90,85))
group_b <- data.frame(id= c(6,7,8,9,10),
test=c(70,83,65,95,80))
group_all <- bind_rows(group_a, group_b)
group_all
# table(is.na(df)) 결측치 빈도 출력
# FALSE  TRUE
#   9     1
# 항목별 결측치 빈도 출력
table(is.na(df$sex))
table(is.na(df$score))
# 결측치가 있는 행 추출
df %>% filter(is.na(score))
df %>% filter(!is.na(score))
df_nomiss2 <- na.omit(df)
df_nomiss2
df_nomiss2 <- na.omit(df)
df_nomiss2
exam[c(3,8,15), "math"] <- NA # 3,8,15행의 math에 NA 할당
exam
mean(df$score, na.rm = T)
exam %>% summarise(mean_math = mean(math))
library(dplyr)
exam <- read.csv("csv_exam.csv")
exam
exam[c(3,8,15), "math"] <- NA # 3,8,15행의 math에 NA 할당
exam
exam %>% summarise(mean_math = mean(math)) # math의 평균 산출
mean(exam$math, na.rm = T)
exam$math <- ifelse(is.na(exam$math), 55, exam$math)
table(is.na(exam$math))
table(is.na(exam$math))
exam$matㅗ
exam$math
# FALSE
# 20
exam
outlier <- data.frame(sex = c(1,2,1,3,2,1),
score = c(5,4,3,4,2,6))
outlier
outlier$sex <- ifelse(outlier$sex == 3, NA, outlier$sex)
outlier
outlier$score <- ifelse(outlier$score == 3, NA, outlier$score)
outlier
outlier %>%
filter(!is.na(sex) & !is.na(score)) %>%
outlier %>%
filter(!is.na(sex) & !is.na(score)) %>% #결측치 제외하기
group_by(sex) %>%  # 집단별로 요약하기
summarise(mean_score = mean(score))
outlier
outlier %>%
filter(!is.na(sex) & !is.na(score)) %>% #결측치 제외하기
group_by(sex) %>%  # 집단별로 요약하기
summarise(mean_score = mean(score)) # 평균값 구하기
# 이상치 제거하기- 극단적인 값
bodxplot(mpg$hwy)
boxplot(mpg$hwy)
# 이상치 제거하기- 극단적인 값
boxplot(mpg$hwy)stats
boxplot(mpg$hwy)stats
boxplot(mpg$hwy)$stats
mpg$hwy <- ifelse(mpg$hwy < 12 | mpg$hwy >37, NA, mpg$hwy)
table(is.na(mpg$hwy))
library(ggplot2)
#1단계
ggplot(data = mpg, aes(x=displ, y=hwy))
ggplot(data = mpg, aes(x=displ, y=hwy)) + geom_point()
ggplot(data = mpg, aes(x=displ, y=hwy)) + geom_point()+xlim(3, 6
ggplot(data = mpg, aes(x=displ, y=hwy)) + geom_point()+xlim(3, 6)
ggplot(data = mpg, aes(x=displ, y=hwy)) + geom_point()+xlim(3, 6)
#막대그래프(BAR CHART)
library(dplyr)
df_mpg
df_mpg <- mpg %>%
group_by(drv) %>%
summarise(mean_hwy = mean(hwy))
df_mpg
df_mpg <- mpg %>%
group_by(drv) %>%
summarise(mean_hwy = mean(hwy))
df_mpg <- mpg %>%
group_by(drv) %>%
summarise(mean_hwy = mean(hwy))
# drv   mean_hwy
# <chr>    <dbl>
#   1 4         19.2
# 2 f         28.2
# 3 r         21
df_mpg
# 그래프 생성
ggplot(data = df_mpg, aes(x = drv, y = mean_hwy)) + geom_col()
# 선 그래프
ggplot(data = df_mpg, aes(x = date, y = unemploy)) + geom_line()
ggplot(data = df_mpg, aes(x = date, y = unemploy)) + geom_line()
# 워드 클라우드(단어의 빈도를 구름 모양으로 표현한 그래프)
install.packages("worldcloud")
library(worldcloud)
library(worldcloud)
install.packages("wordcloud")
library(wordcloud)
library(RColorBrewer)
# 난수(무작위로 생성한 수) 고정하기[함수를 실행할 때 마다 매번 다른 모양의 워드 클라우드를 만들어내므로]
set.seed(1234)
install.packages("multilinguer")
library(multilinguer)
install_jdk
install_jdk()
install.packages("stringr", "hash", "tau", "Sejong", "RSQLite", "devtools"), type = "binary")
install.packages("stringr", "hash", "tau", "Sejong", "RSQLite", "devtools"), type = "binary")
install.packages(c("stringr", "hash", "tau", "Sejong", "RSQLite", "devtools"), type = "binary")
install.packages("remotes")
remotes :: install_github(" haven-jeon/KoNLP",
upgrade = "never",
INSTALL_opts = c("--no-multiarch"))
mpg_diff2 <- mpg %>%
select(f1, cty) %>%
filter(f1 %in% c("r", "p")) # r: regular , p: premeium
library(dplyr)
mpg_diff2 <- mpg %>%
select(f1, cty) %>%
filter(f1 %in% c("r", "p")) # r: regular , p: premeium
source("D:/WORKSPACE(SHIN)/github/MYSELF24/workscripts/books/Datanalysis_Doit/Part 1/easy_r/13-2 statitical similarity.R", echo=TRUE)
mpg
mpg <- as.data.frame(ggplot2::mpg)
mpg_diff2 <- mpg %>%
select(f1, cty) %>%
filter(f1 %in% c("r", "p")) # r: regular , p: premium
mpg
mpg_diff2 <- mpg %>%
select(fl, cty) %>%
filter(fl %in% c("r", "p")) # r: regular , p: premium
table(mpg_diff2$fl)
t.test(data = mpg_diff2, cty - fl, var.equal = T)
mpg_diff2 <- mpg %>%
select(fl, cty) %>%
filter(fl %in% c("r", "p")) # r: regular , p: premium
mpg_diff2 <- mpg %>%
mpg_diff2
mpg_diff2 <- mpg %>%
select(fl, cty) %>%
filter(fl %in% c("r", "p")) # r: regular , p: premium
mpg_diff2
t.test(data = mpg_diff2, cty - fl, var.equal = T)
t.test(data = mpg_diff2, cty ~ fl, var.equal = T)
economics <- as.data.frame(ggplot2::economics)
cor.test(economics$unemploy, economics$pce)
source("D:/WORKSPACE(SHIN)/github/MYSELF24/workscripts/books/Datanalysis_Doit/Part 1/easy_r/10-1 TEXT MINING.R", echo=TRUE)
install.packages("remotes")
install.packages(c("stringr", "hash", "tau", "Sejong", "RSQLite", "devtools"), type = "binary")
df_word
install.package("KoNLP")
install.package("KoNLP")
install_jdk()
install.packages("multilinguer")
install.packages("multilinguer")
2library(multilinguer)
library(multilinguer)
install_jdk()
install_jdk()
install.packages("remotes")
remotes :: install_github(" haven-jeon/KoNLP",
upgrade = "never",
INSTALL_opts = c("--no-multiarch"))
install.packages("remotes")
install.packages("stringr")
library(stringr)
install.packages("stringr")
txt <- str_replace_all(txt, "\\W", " ")
library(stringr)
txt <- str_replace_all(txt, "\\W", " ")
txt <- readLines("hiphop.txt")
head(txt)
# 문장에 있는 특수문자 제거( \\W는 특수문자를 나타내는 정규 표현식(regular expression) 정규 표현식을 이용하면 문장의 내용 중 #이메일 주소, 전화번호 처럼 특정한 규칙으로 되어 있는 부분을 추출가능
txt <- str_replace_all(txt, "\\W", " ")
txt <- str_replace_all(txt, "\\W", " ")
txt
extractNoun("대한민국의 영토는 한반도와 그 부속도서로 한다")
#명사 추출하기
extractNoun("대한민국의 영토는 한반도와 그 부속도서로 한다")
library(KoNLP)
library(KoNLP)
library(stringr)
library(multilinguer)
library(wordcloud)
library(RColorBrewer)
extractNoun("대한민국의 영토는 한반도와 그 부속도서로 한다")
library(KoNLP)
extractNoun("대한민국의 영토는 한반도와 그 부속도서로 한다")
library(multilinguer)
library(KoNLP)
library(stringr)
extractNoun("대한민국의 영토는 한반도와 그 부속도서로 한다")
# 결과
Pearson's product-moment correlation
data:  economics$unemploy and economics$pce
t = 18.63, df = 572, p-value < 2.2e-16
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
0.5608868 0.6630124
sample estimates:
cor
0.6145176
p-value < 2.2e-16 # 0.05미만이므로 실업자 숭와 개인 소비 지출의 상관이 통계적으로 유의적임
cor : 0.6145176 # 실업자 수와 개인 소비 지출은 한 변수가 증가하면 다른 변수가 증가하는 정비례 관계
#====================================================================================================#
# 상관행렬(correlation matrix) 히트맵 만들기
# mtcats 데이터셋
- mpg: 연비
- cyl: 실린더 수
# wt: 무게
cor()
cor()
# 결과
Pearson's product-moment correlation
head(mtcars)
# 결과
Pearson's product-moment correlation
data:  economics$unemploy and economics$pce
t = 18.63, df = 572, p-value < 2.2e-16
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
0.5608868 0.6630124
sample estimates:
cor
0.6145176
p-value < 2.2e-16 # 0.05미만이므로 실업자 숭와 개인 소비 지출의 상관이 통계적으로 유의적임
cor : 0.6145176 # 실업자 수와 개인 소비 지출은 한 변수가 증가하면 다른 변수가 증가하는 정비례 관계
#====================================================================================================#
# 상관행렬(correlation matrix) 히트맵 만들기
# mtcats 데이터셋
- mpg: 연비
- cyl: 실린더 수
# wt: 무게
cor()을 이용하면 상관행렬을 만들 수 있음
head(mtcars)
#                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
# Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
# Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
# Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
# Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
# Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
# Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
car_cor <- cor(mtcars)
# 결과
Pearson's product-moment correlation
# 결과
Pearson's product-moment correlation
data:  economics$unemploy and economics$pce
t = 18.63, df = 572, p-value < 2.2e-16
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
0.5608868 0.6630124
sample estimates:
cor
0.6145176
p-value < 2.2e-16 # 0.05미만이므로 실업자 숭와 개인 소비 지출의 상관이 통계적으로 유의적임
cor : 0.6145176 # 실업자 수와 개인 소비 지출은 한 변수가 증가하면 다른 변수가 증가하는 정비례 관계
#====================================================================================================#
# 상관행렬(correlation matrix) 히트맵 만들기
# mtcats 데이터셋
- mpg: 연비
- cyl: 실린더 수
# wt: 무게
cor()을 이용하면 상관행렬을 만들 수 있음
head(mtcars)
#                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
# Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
# Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
# Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
# Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
# Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
# Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
car_cor <- cor(mtcars)
car_cor <- cor(mtcars)
round(car_cor, 2) # 소수점 셋째 자리에서 반올림 해서 출력
# 결과
Pearson's product-moment correlation
source("~/.active-rstudio-document", echo=TRUE)
install.packages("corplot")
install.packages("corrplot")
library(corrplot)
# 결과
Pearson's product-moment correlation
data:  economics$unemploy and economics$pce
t = 18.63, df = 572, p-value < 2.2e-16
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
0.5608868 0.6630124
sample estimates:
cor
0.6145176
p-value < 2.2e-16 # 0.05미만이므로 실업자 숭와 개인 소비 지출의 상관이 통계적으로 유의적임
cor : 0.6145176 # 실업자 수와 개인 소비 지출은 한 변수가 증가하면 다른 변수가 증가하는 정비례 관계
#====================================================================================================#
# 상관행렬(correlation matrix) 히트맵 만들기
# mtcats 데이터셋
- mpg: 연비
- cyl: 실린더 수
# wt: 무게
cor()을 이용하면 상관행렬을 만들 수 있음
head(mtcars)
# mtcars는 자동차 32종의 11개 속성에 대한 정보를 담고 있는 데이터
#                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
# Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
# Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
# Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
# Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
# Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
# Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
car_cor <- cor(mtcars)
round(car_cor, 2) # 소수점 셋째 자리에서 반올림 해서 출력
install.packages("corrplot")
library(corrplot)
corrplot(car_cor)
corrplot(car_cor)
corrplot(car_cor)
